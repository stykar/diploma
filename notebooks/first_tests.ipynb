{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b8f18b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "import optuna\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from diploma.utils.functions import objective\n",
    "\n",
    "from sklearn import svm, preprocessing\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a4a4cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_LOX = pd.read_csv('../data/training_set_LOX.csv')\n",
    "df_train_ANT = pd.read_csv('../data/training_set_antioxidant.csv')\n",
    "df_test = pd.read_csv('../data/test_set.csv')\n",
    "\n",
    "#drop title column\n",
    "df_train_LOX = df_train_LOX.drop(columns = ['Title'], axis = 1)\n",
    "df_train_ANT = df_train_ANT.drop(columns = ['Title'], axis = 1)\n",
    "df_test = df_test.drop(columns = ['Title'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4721a72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace NaN values in each file with mean of column\n",
    "\n",
    "mean_values_LOX = df_train_LOX.mean()\n",
    "mean_values_ANT = df_train_ANT.mean()\n",
    "\n",
    "df_train_LOX = df_train_LOX.fillna(mean_values_LOX)\n",
    "df_train_ANT = df_train_ANT.fillna(mean_values_ANT)\n",
    "\n",
    "#merge LOX and ANT arrays\n",
    "frames = [df_train_LOX, df_train_ANT]\n",
    "merged_train = pd.concat(frames)\n",
    "merged_train.shape\n",
    "\n",
    "train_set = merged_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c1fa0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalization\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "cols = train_set.columns\n",
    "d = scaler.fit_transform(train_set)\n",
    "train_set = pd.DataFrame(d, columns=cols)\n",
    "\n",
    "cols = df_test.columns\n",
    "d = scaler.fit_transform(df_test)\n",
    "df_test = pd.DataFrame(d, columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1052288a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#form data for tests\n",
    "x = train_set.loc[:, train_set.columns != 'class']\n",
    "y = train_set.iloc[:,0]\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa1b9e6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.93548387 0.93946731 0.94350282 0.93946731 0.94027441]\n"
     ]
    }
   ],
   "source": [
    "#Calculate logistic regression with KFold cross validation\n",
    "\n",
    "kfold = KFold(n_splits=5, random_state=0, shuffle=True)\n",
    "lr_model = LogisticRegression(solver='liblinear', max_iter = 500)\n",
    "results = cross_val_score(lr_model, x, y, cv=kfold)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44d06b29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94435484 0.96125908 0.94511703 0.95157385 0.94027441]\n"
     ]
    }
   ],
   "source": [
    "#Create a svm Classifier\n",
    "svm_model = svm.SVC(random_state=1, probability=True)\n",
    "\n",
    "svm_model.fit(x_train, y_train)\n",
    "\n",
    "results = cross_val_score(svm_model, x, y, cv=kfold)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1536d4af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.93064516, 0.90637611, 0.85875706, 0.84100081, 0.68926554])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Decision Tree Classifier\n",
    "\n",
    "dtc_model = DecisionTreeClassifier(max_depth=10, random_state=0)\n",
    "dtc_model.fit(x,y)\n",
    "cross_val_score(dtc_model, x, y, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b87797d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.925     , 0.93058918, 0.87409201, 0.86521388, 0.93866021])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Random Forest Classifier\n",
    "\n",
    "rfc_model = RandomForestClassifier(max_depth=10, random_state=0)\n",
    "rfc_model.fit(x, y)\n",
    "cross_val_score(rfc_model, x, y, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c2f8bfb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-11 14:42:02,493]\u001b[0m A new study created in memory with name: no-name-c50d04cf-743e-483e-8dac-8a5f19f1a11d\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#Find best parameters for LGBMClassifier\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "func = lambda trial: objective(trial, x.to_numpy(), y.to_numpy())\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "study.optimize(func, n_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1de63ccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of finished trials: 100\n",
      "Best trial:\n",
      "  Value: 0.9974176888315042\n",
      "  Params: \n",
      "    lambda_l1: 4.5022521974395696e-05\n",
      "    lambda_l2: 6.695262212853087e-06\n",
      "    num_leaves: 173\n",
      "    feature_fraction: 0.6012173189079907\n",
      "    bagging_fraction: 0.854547120407732\n",
      "    bagging_freq: 5\n",
      "    min_child_samples: 85\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of finished trials: {}\".format(len(study.trials)))\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print(\"  Value: {}\".format(trial.value))\n",
    "\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "95f19a38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.6012173189079907, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6012173189079907\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.5022521974395696e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.5022521974395696e-05\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.854547120407732, subsample=1.0 will be ignored. Current value: bagging_fraction=0.854547120407732\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.695262212853087e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.695262212853087e-06\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMRegressor(bagging_fraction=0.854547120407732, bagging_freq=5,\n",
       "              feature_fraction=0.6012173189079907,\n",
       "              lambda_l1=4.5022521974395696e-05, lambda_l2=6.695262212853087e-06,\n",
       "              min_child_samples=85, num_leaves=173)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb_model = lgb.LGBMRegressor(**study.best_params)\n",
    "lgb_model.fit(x_train.to_numpy(), y_train.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f30e3ebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM results:\n",
      "Training accuracy 0.95319\n",
      "Testing accuracy 0.82617\n"
     ]
    }
   ],
   "source": [
    "print('LightGBM results:')\n",
    "print(f'Training accuracy {lgb_model.score(x_train,y_train):.5f}')\n",
    "print(f'Testing accuracy {lgb_model.score(x_test,y_test):.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c3b42066",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.43709231, 0.73223799, 0.45227682, 0.5099205 , 0.72337504,\n",
       "       0.74555534, 0.34125417, 0.355734  , 0.27522441, 0.36343678,\n",
       "       0.40305118, 0.36393379, 0.41526117, 0.65381958, 0.94833954,\n",
       "       0.82038917, 0.60500225, 0.69388021, 0.83230369, 0.91553031,\n",
       "       0.91553031, 0.55629355, 0.68021774, 0.5177364 ])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb_model.predict(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "152b1d31",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of binary and continuous targets",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_2192\\2439681448.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0my_test_temp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test_temp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlgb_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'class 0'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'class1'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36mclassification_report\u001b[1;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[0;32m   2108\u001b[0m     \"\"\"\n\u001b[0;32m   2109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2110\u001b[1;33m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2111\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2112\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 93\u001b[1;33m         raise ValueError(\n\u001b[0m\u001b[0;32m     94\u001b[0m             \"Classification metrics can't handle a mix of {0} and {1} targets\".format(\n\u001b[0;32m     95\u001b[0m                 \u001b[0mtype_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtype_pred\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Classification metrics can't handle a mix of binary and continuous targets"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_test_temp = np.expand_dims(y_test.to_numpy(), axis=-1)\n",
    "\n",
    "print(classification_report(y_test_temp, lgb_model.predict(x_test), target_names=['class 0', 'class1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb9026e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_model.predict(x_test).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d88fd8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "d997f875e43a0eadbed7c25aa6575c5c6bf4e09655b7ae816e13c2596481ac19"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
